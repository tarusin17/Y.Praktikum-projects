{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Machine_learning_for_texts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwA6PSmkDN4x",
        "colab_type": "text"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Нужно обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "\n",
        "\n",
        "### Описание данных\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr2aiHQvDN41",
        "colab_type": "text"
      },
      "source": [
        "# 1. Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eSWwEIZDN4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "from tqdm import notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ior4buO8DN5S",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ea5dc37-fe8d-4d23-ac9d-31a3b6abe642"
      },
      "source": [
        "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYZ_4EZIDN5j",
        "colab_type": "text"
      },
      "source": [
        "Напишем функции для лемматизации и очистки текстаю"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM_GlqNmDN5l",
        "colab_type": "code",
        "colab": {},
        "outputId": "05fbbc12-8c0e-4f1f-9a3b-148bc796532e"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatize(text):\n",
        "    m = WordNetLemmatizer()\n",
        "    lemm_list = m.lemmatize(text)\n",
        "    lemm_text = \"\".join(lemm_list)\n",
        "        \n",
        "    return lemm_text\n",
        "\n",
        "\n",
        "def clear_text(text):\n",
        "    re_list = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
        "    re_list = re_list.split()\n",
        "    re_list = \" \".join(re_list)\n",
        "    return re_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm6LyUotDN50",
        "colab_type": "text"
      },
      "source": [
        "Создадим корпус из очищенных текстов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM7nssMqDN53",
        "colab_type": "code",
        "colab": {},
        "outputId": "081d0487-5d9b-4c8b-f2b8-ab47e3aded94"
      },
      "source": [
        "%%time\n",
        "corpus = list(df['text'].apply(lambda x: lemmatize(clear_text(x))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 s, sys: 270 ms, total: 10.5 s\n",
            "Wall time: 10.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQTvGqPnDN6F",
        "colab_type": "text"
      },
      "source": [
        "Переведем тексты в вектора и создадим матрицу с оценками важности слов. Она будет использоваться в качестве features в наших моделях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmgeWN09DN6H",
        "colab_type": "code",
        "colab": {},
        "outputId": "593c69ab-557c-4e02-fa9c-6cc0ccb20f6b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
        "tf_idf = count_tf_idf.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xxQ2o-fDN6Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "f5282f68-48a5-4fae-e0fe-9c3a6e64043f"
      },
      "source": [
        "tf_idf.shape, df['toxic'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((159571, 168645), (159571,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAgzENDZDN6v",
        "colab_type": "text"
      },
      "source": [
        "# 2. Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU8PTtRaDN6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = tf_idf\n",
        "target = df['toxic'].values\n",
        "\n",
        "\n",
        "train_features, valid_feature, train_target, valid_target = train_test_split(features, \n",
        "                                                                           target, \n",
        "                                                                           test_size=0.2, \n",
        "                                                                           random_state=42)\n",
        "\n",
        "valid_features, test_features, valid_target, test_target = train_test_split(valid_feature, \n",
        "                                                                           valid_target, \n",
        "                                                                           test_size=0.5,\n",
        "                                                                           random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfG3KYSnDN7I",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2baaea7-073c-4ade-f438-9f5bdd2c1704"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfvA3pWvDN7Y",
        "colab_type": "text"
      },
      "source": [
        "Обучим несколько моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIBVQdE0DN7c",
        "colab_type": "code",
        "colab": {},
        "outputId": "cc060795-933f-4ecd-c8dd-582df198491a"
      },
      "source": [
        "%%time\n",
        "\n",
        "reg_model = LogisticRegression(class_weight = 'balanced')\n",
        "reg_model.fit(train_features, train_target)\n",
        "prediction = reg_model.predict(valid_features)\n",
        "f1 = f1_score(valid_target, prediction)\n",
        "print('F1 логистической регрессии:', f1)\n",
        "print()\n",
        "print('Матрица ошибок')\n",
        "print(confusion_matrix(valid_target, prediction))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 логистической регрессии: 0.7532608695652175\n",
            "\n",
            "Матрица ошибок\n",
            "[[13663   647]\n",
            " [  261  1386]]\n",
            "\n",
            "CPU times: user 7.2 s, sys: 6.41 s, total: 13.6 s\n",
            "Wall time: 13.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQmIXMMDN7s",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7cd8d9f-8ab0-470b-b242-70f3b6efa728"
      },
      "source": [
        "%%time\n",
        "\n",
        "cat_model = CatBoostClassifier(eval_metric=\"F1\", \n",
        "                                   iterations=100, \n",
        "                                   max_depth=6, \n",
        "                                   learning_rate=0.9, \n",
        "                                   random_state=42)\n",
        "cat_model.fit(train_features, train_target, verbose=20)\n",
        "prediction = cat_model.predict(valid_features)\n",
        "f1 = f1_score(valid_target, prediction)\n",
        "print('F1 CatBoost:', f1)\n",
        "print()\n",
        "print('Матрица ошибок')\n",
        "print(confusion_matrix(valid_target, prediction))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.4077145\ttotal: 6.74s\tremaining: 11m 7s\n",
            "20:\tlearn: 0.7365763\ttotal: 1m 59s\tremaining: 7m 28s\n",
            "40:\tlearn: 0.7697634\ttotal: 3m 51s\tremaining: 5m 33s\n",
            "60:\tlearn: 0.7898848\ttotal: 5m 44s\tremaining: 3m 40s\n",
            "80:\tlearn: 0.8029253\ttotal: 7m 39s\tremaining: 1m 47s\n",
            "99:\tlearn: 0.8113825\ttotal: 9m 26s\tremaining: 0us\n",
            "F1 CatBoost: 0.7601224906430758\n",
            "\n",
            "Матрица ошибок\n",
            "[[14135   175]\n",
            " [  530  1117]]\n",
            "\n",
            "CPU times: user 11min 2s, sys: 16.7 s, total: 11min 19s\n",
            "Wall time: 11min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91UkbjrIDN77",
        "colab_type": "text"
      },
      "source": [
        "Лучший результат получается у CatBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9LPc7uGDN79",
        "colab_type": "text"
      },
      "source": [
        "# 3. Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTBArgIeDN8C",
        "colab_type": "text"
      },
      "source": [
        "Проверим модели на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPao1qofDN8H",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef426a38-510a-40c4-9c33-d8ffeb216e10"
      },
      "source": [
        "prediction = cat_model.predict(test_features)\n",
        "f1 = f1_score(test_target, prediction)\n",
        "print('F1 CatBoost:', f1)\n",
        "print()\n",
        "print('Матрица ошибок')\n",
        "print(confusion_matrix(test_target, prediction))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 CatBoost: 0.7551954913702007\n",
            "\n",
            "Матрица ошибок\n",
            "[[14191   170]\n",
            " [  525  1072]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7w1Hov_DN8Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "3cd56dbc-f00e-4dbf-999e-4732daf1806f"
      },
      "source": [
        "prediction = reg_model.predict(test_features)\n",
        "f1 = f1_score(test_target, prediction)\n",
        "print('F1 регрессии:', f1)\n",
        "print()\n",
        "print('Матрица ошибок')\n",
        "print(confusion_matrix(test_target, prediction))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 регрессии: 0.756179775280899\n",
            "\n",
            "Матрица ошибок\n",
            "[[13744   617]\n",
            " [  251  1346]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNSIWnOSDN8e",
        "colab_type": "text"
      },
      "source": [
        "#### Вывод\n",
        "Обе модели имеют одинаковое значение метрики F1. Но, как мы видим из матрицы ошибок, у модели регрессии больше ложноположительных ответов и меньше ложно отрицательных. У CatBoost наоборот - больше ложно отрицательных и меньше ложноположительных. \n",
        "На мой взляд, для бизнасе будет полезнне модель, которая меньше ошибается в определении отрицательных комментариев, чем положительных. Потому что положительный комментарий можно промодерировать вручную и вернуть, а чем меньше мдель пропускает негативных комментариев, тем лучше.\n",
        "\n",
        "Такрим образом, для бизнеса, лучше подходит модель **линейной регрессии**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je5756GvDN8m",
        "colab_type": "text"
      },
      "source": [
        "# 4. BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEmNFe4xDN8o",
        "colab_type": "text"
      },
      "source": [
        "Попытка применить модель предобученную модель BERT. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctaU6-xhDN8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
        "df_comments = df_comments.sample(400).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlUt5JZdDN88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = transformers.BertTokenizer(vocab_file='vocab.txt')\n",
        "tokenized = df_comments['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=400))\n",
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "        \n",
        "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
        "attention_mask = np.where(padded != 0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX5rP57vDN9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = transformers.BertConfig.from_json_file('bert_config.json')\n",
        "model = transformers.BertModel.from_pretrained('pytorch_model.bin', config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OooJzX_gDN9d",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "6fd7b85fc05f4101b3c3debb7feb5249"
          ]
        },
        "outputId": "d441bf37-8368-4cb6-9e35-0dffd1b872f0"
      },
      "source": [
        "\"\"\"batch_size = 40\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
        "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "    embeddings.append(batch_embeddings[0][:,0,:])\"\"\"\n",
        "\n",
        "#Срок выполнения - 25 минут. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fd7b85fc05f4101b3c3debb7feb5249",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl1avDwQDN9s",
        "colab_type": "code",
        "colab": {},
        "outputId": "3accadf8-c0c1-45c2-c83e-fafe64b45ca3"
      },
      "source": [
        "features_bert = np.concatenate(embeddings)\n",
        "target_bert = df_comments['toxic']\n",
        "\n",
        "train_features_bert, test_features_bert, train_target_bert, test_target_bert = train_test_split(features_bert, \n",
        "                                                                                                target_bert, \n",
        "                                                                                                test_size=0.2, \n",
        "                                                                                                random_state = 42)\n",
        "\n",
        "bert_model = LogisticRegression(class_weight = 'balanced')\n",
        "bert_model.fit(train_features_bert, train_target_bert)\n",
        "prediction_bert = bert_model.predict(test_features_bert)\n",
        "f1_bert = f1_score(test_target_bert, prediction_bert)\n",
        "print('F1 BERT:', f1_bert)\n",
        "print()\n",
        "print('Матрица ошибок')\n",
        "print(confusion_matrix(test_target_bert, prediction_bert))\n",
        "print()\n",
        "\n",
        "\n",
        "#F1 = 0.70\n",
        "#Матрица ошибок\n",
        "#[[69  2]\n",
        "# [ 3  6]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 BERT: 0.7058823529411765\n",
            "\n",
            "Матрица ошибок\n",
            "[[69  2]\n",
            " [ 3  6]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}